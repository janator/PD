## Домашнее задание по HDFS

В этом домашнем задании Вам предстоит поближе познакомиться с [распределенной файловой системой HDFS](http://hadoop.apache.org/docs/r1.2.1/hdfs_design.html). Ваша цель - написать скрипты, которые будут делать HTTP запросы к различным демонам HDFS или вызывать стандартные утилиты командной строки (shell) с целью получения запрашиваемой информации.

Можно использовать любой скриптовый язык программирования. Самый простой вариант - использовать bash, а также утилиты curl, grep, wc и т.п.

<p>
<details>
<summary markdown="span"><h3> Сроки сдачи </h3></summary>

| Группа | Soft deadline | Hard deadline (-50%) |
| ---      |  ------  |------|
|Б05-812|07.11, 23:59|14.11, 23:59|
|Б05-824 и Б05-825|07.11, 23:59|14.11, 23:59|
|Б05-822|01.11, 23:59|08.11, 23:59|
|Б05-811|02.11, 23:59|09.11, 23:59|
|Б05-821 и Б05-831|02.11, 23:59|09.11, 23:59|
|Б05-813|03.11, 23:59|10.11, 23:59|
|Б05-823|03.11, 23:59|10.11, 23:59|
|Б05-826|03.11, 23:59|10.11, 23:59|

Исправлять коды после комментариев можно в течение месяца после проверки.

</details>
</p>


### Подготовка кода для сдачи
Для каждой домашки имеются предваритиельно созданные репозитории с веткой master и ветками для каждой задачи в домашке. Для сдачи домашки нужно:
1. В каждой ветке в корень положить файл `.gitlab-ci.yml` такого содержания:
```yml
job1:
  except:
    - master
  script:
    - date
    - if [ `grep -v '#' ${CI_COMMIT_REF_NAME}/run.sh | wc -l` -gt 0 ]; then (cd ~/code; ./gitlab_ci_runner.py); else exit 1; fi
```
(можно взять [отсюда](http://gitlab.atp-fivt.org/root/demos/blob/ci_files/.gitlab-ci.yml))

2. В каждой ветке создать директорию, имя директории = имени ветки. Например, нужно создать директории с названиями `hdfstask1` и `hdfstask2` в ветках `hdfstask1` и `hdfstask2` соотвественно.

3. В созданных директориях положите файл `run.sh`. Это точка входа в вашу программу и именно её будет запускать система проверки. В `run.sh` может быть как всё решение задачи так и вызов других файлов.

> Даже если разрабатываете на Python, `run.sh` может содержать только вызов нужного скрипта, например: 
> 
> 	#!/usr/bin/env bash
> 	
> 	python my_python_script.py $*
>
> Тут $* обеспечит передачу параметров, с которыми был вызван `run.sh` в `my_python_script.py`.

### Задачи

#### 01 (0.1 балла)
На вход скрипту подается имя файла, на выходе нужно получить имя сервера или IP-адрес, с которого будет читаться первый блок данных (реплик может быть несколько, засчитываться будет любой из них). Пример:

	$ ./run.sh /data/access_logs/big_log/access.log.2015-12-10
	mipt-node01.atp-fivt.org

#### 02 (0.1 балла)
На вход скрипту подается имя файла, на выходе нужно получить первые 10 байт этого файла (hadoop fs и hdfs dfs использовать нельзя)

	$ ./run.sh /data/access_logs/big_log/access.log.2015-12-10
	41.190.60.

#### 03 (0.1 балла)
На вход скрипту подается полный путь до файла в HDFS, на выходе нужно получить размер файла в блоках (см. hdfs fsck -h).

	$ ./run.sh /data/access_logs/big_log/access.log.2015-12-10	
	8

#### 04 (0.3 балла)

На вход скрипту подается идентификатор блока, на выходе нужно получить имя сервера (если их несколько, то выбрать любой), где хранится данный блок и физический путь в локальной файловой системе до этого блока данных. (О том, как зайти на ноды кластера, написано в материалам [cеминара по HDFS](/distribute/practice/01-hdfs.md))

	$ ./run.sh blk_1075127191
	bds03.vdi.mipt.ru:/dfs/dn/current/BP-76251478-10.55.163.141-1427134131440/current/finalized/subdir21/subdir35/blk_1075127191

#### 05 (0.4 балла)
Большие файлы на кластере делятся на блоки определенного размера. Нужно выяснить какой дополнительный объем используется в HDFS для хранения данных при использовании одной реплики (т.е. без дублирования данных). Для проведения экспериментов и создания файлов разного размера предлагается использовать утилиту dd (см. [пример использования](http://unix.stackexchange.com/questions/101332/generate-file-of-a-certain-size)) + решение задачи 4. На вход программы подается размер файла в байтах, на выходе программы должно быть одно число, равное числу байт для физического хранения этого файла (без учета хранения файлов с расширением .meta). Из полученного результата вычесть объём исходного файла (в байтах).

	$ ./run.sh <int>
	123
